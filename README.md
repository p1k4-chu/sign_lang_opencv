## Sign Language
The goal of this project is to build a real-time system that can:

Capture video using a webcam.

Detect and segment the hand region.

Extract features from hand gestures.

Classify gestures into predefined sign language symbols.

This project serves as a foundation for gesture-based communication systems and can be extended to full sign-language translation.
The goal of this project is to recognize hand gestures representing sign language alphabets/numbers using computer vision.
The system captures hand gesture images through a webcam, trains a classification model on custom-collected data, and performs real-time prediction via a web app.